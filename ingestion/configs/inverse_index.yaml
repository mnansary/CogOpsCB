# ===================================================================
# Configuration for the Elasticsearch Mixed-Language Indexing Pipeline
# ===================================================================

# --- Data Source Configuration ---
# Specifies where to find the input data and which columns to use.
data_source:
  # The relative or absolute path to your input CSV file.
  csv_path: "/home/vpa/downloads/data/processed_data_20250830.csv"

  # The name of the column in the CSV that contains the unique ID for each passage.
  id_column: "passage_id"

  # The name of the column that contains the mixed Bangla and English text.
  source_text_column: "passage"


# --- Elasticsearch Configuration ---
# Settings related to the Elasticsearch instance and the target index.
elasticsearch:
  # The name of the index you want to create or update in Elasticsearch.
  # Using version numbers (e.g., v1, v2) is a good practice for easier migrations.
  index_name: "govt_services_passages_latest"

  # The names of the fields that will be created within each document in the index.
  # This allows for easy modification without changing the core code.
  fields:
    # Field to store the original, untouched text. Useful for display.
    raw: "passage_raw"

    # Field to be processed by Elasticsearch's built-in English analyzer (stemming, stopwords).
    english_analyzed: "passage_en"

    # Field to be processed by Elasticsearch's built-in Bengali analyzer (normalization).
    bengali_analyzed: "passage_bn"

    # Field to store the Bengali text after it has been pre-stemmed in Python.
    bengali_stemmed: "passage_bn_stemmed"